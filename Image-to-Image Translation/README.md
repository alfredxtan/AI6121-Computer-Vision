This is the final project on image-to-image translation (I2I), using CycleGAN and unsupervised domain adaptation (UDA) using CyCADA. 

In the first part of the project, we performed I2I using the MNIST dataset and the SVHN dataset. The use of CycleGAN for this task allows us to perform 
the translation in both directions (from MNIST to SVHN and vice versa). 

In the second part of the project, we performed UDA between MNIST and USPS datasets, with the source images as MNIST and target images as USPS.
This allows us to make use of the labelled USPS dataset to train a classifier for unlabelled MNIST images.

Acknowledgement of the codes are in the final report.
